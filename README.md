# EagleView-DL-ML-Assignment-for-Data-Scientist
## Brief Explanation
After importing required libraries, I created a dataframe of the image dataset with the labels on them namely, 'Person' and 'Car'. I created three sets of the data as train, validation and test then trained the convolutional neural network which is the best model for image classification of such types of projects. It has two layers of Conv2D which has relu activation function 2 of MaxPoollayer, 1 Global average pooling layer and 2 Dense layers. In the output layer sigmoid activation is used because this is a binary classification problem and the sigmoid function gives 1 or 0 as an output. The model gained 49.33% of accuracy and 0.69 of loss. In the end precision, recall, f1 score along with the confusion matrix has been calculated. I tested the model with a different image downloaded from the internet and the model accurately classifies it.

## Getting Started
From the given dataset I partitioned it in two categories- Cars and Person having 1117, 1122 in each. I am going to be using a keras convolutional neural network and for preprocessing the data I will use numpy, pandas, path object from pathlib and os.path then I am using confusion metric from seaborn. For train and test split I am using train test split function from sklearn and make the model with tensorflow.

## Construct a dataframe
I am creating a dataframe that contains one column with the lable of each image and such dataframe in essential if I am going to use flow from dataframe function from keras' image data generator. Flow from diractory is a function that automatically pulls images from the directories without loading all of them into memory at once. When using flow from direcories it's best to have train test split beforhand already within the direcories so I am using flow from dataframe which allows to manipulate which image we want to use. I am going to take the imagedir which is actually a path object and use the glob function on it and the glob allows you to specify a glob expression to search for files within the folder so we are looking for anything followed by a jpg file withing the current folder now it is a generator object.

## Creating the model
Now I split the dataframe in train and test with 70% of train size and keep the shuffle true. I load the image data so I am not going to load it into memory yet but specify how it will be loaded into memory at the time of training and for that I use generator tf.keras.preprocessing image data generator it allows us to load in only a batch of images at a time, perform the training on them and then recycle the memory so we don't run out. For preprocessing, I rescale the images by a factor of 1 over 255 which has the effect of scaling the pixel intensity values from its original scale of 0 to 255 down to 0 to 1. Last thing I want to put is the validation split of 20% of all the data. SO I am using 20 percent to validation and the other 80 percent training
